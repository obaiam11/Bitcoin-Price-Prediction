{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS 230 Project Milestone\n",
    "# Dante Zakhidov, Abdulmalik Obaid, Scott Keene\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "# Type the filename of the bitcoin price data file (starting with /)\n",
    "bitcoin_data_filename = r\"C:\\Users\\Penguin\\coinbaseUSD_1-min_data_2014-12-01_to_2018-01-08.csv\"\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "# Import packages for keras\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import keras.backend as K\n",
    "\n",
    "# For reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "def import_data_file(filename):\n",
    "    # Get raw data\n",
    "    BTC_Price = pd.read_csv(bitcoin_data_filename)\n",
    "    \n",
    "    # Identify the Price variance for the each days\n",
    "    # Variance = Close price minus the Open price \n",
    "    # Negative value indicate price has declined for that day and Positive value represent increase in price\n",
    "    BTC_Price['Variance'] = ((BTC_Price[\"Close\"] - BTC_Price[\"Open\"])/BTC_Price[\"Close\"])*100\n",
    "\n",
    "    # Frequeny of change for a given day (High - Low)\n",
    "    BTC_Price['Freq'] = ((BTC_Price[\"High\"] - BTC_Price[\"Low\"])/BTC_Price[\"High\"])*100\n",
    "    \n",
    "    # Create binary classification\n",
    "    BTC_Price['Up_Label'] = (BTC_Price[\"Close\"] > BTC_Price[\"Open\"])\n",
    "    \n",
    "    return BTC_Price\n",
    "\n",
    "# Generate Minute Dataset, will compare performance of model based on daily data\n",
    "\n",
    "# Generate minute by minute training and test set\n",
    "def generate_min_dataset(dataset, num_train, num_dev):\n",
    "    '''Takes the minute by minute data (dataset) and generates a text set X_train, Y_train\n",
    "    Uses set number of train data (num_train) and test data (num_test)\n",
    "    Dataset structure contains:\n",
    "    Timestamp, Open, High, Low, Close, Volume_(BTC), Volume_Currency, Weighted_Price, Variance, Freq'''\n",
    "    \n",
    "    data = dataset.as_matrix()\n",
    "    # Takes X data as (num_train x 10) matrix for inputs\n",
    "    # Takes the Y data as the Up_Label of the following X dataset \n",
    "    X_train = data[1000000:1000000 + num_train, 1:9]\n",
    "    Y_train = data[1000000 + 1:1000000 + num_train + 1, 10]\n",
    "    X_dev = data[1570000 - num_dev:1570000, 1:9]\n",
    "    Y_dev = data[1570000 - num_dev + 1:1570000 + 1, 10]\n",
    "    \n",
    "    return X_train, Y_train, X_dev, Y_dev\n",
    "\n",
    "# Generate Daily Dataset to compare model performance to minute data\n",
    "def generate_daily_dataset(dataset, num_days_train, num_days_dev):\n",
    "    \n",
    "    data = dataset.as_matrix()\n",
    "    min_to_day = 1440\n",
    "    X_train = np.zeros((num_days_train, 8))\n",
    "    Y_train = np.zeros((num_days_train, 1))\n",
    "    X_dev = np.zeros((num_days_train, 8))\n",
    "    Y_dev = np.zeros((num_days_dev, 1))\n",
    "    # Takes the mean of 1440 minutes to get the average price for that day. \n",
    "    for i in range(0, num_days_train):\n",
    "        X_train[i,:] = np.mean(data[i*min_to_day:(i + 1)*min_to_day, 1:9], axis = 0)\n",
    "        X_train[i,1] = data[i*min_to_day, 1]\n",
    "        X_train[i,2] = np.max(data[i*min_to_day:(i + 1)*min_to_day, 2])\n",
    "        X_train[i,3] = np.max(data[i*min_to_day:(i + 1)*min_to_day, 3])\n",
    "        X_train[i,4] = data[i*min_to_day, 4]\n",
    "    for i in range(num_days_train, num_days_train + num_days_dev):    \n",
    "        X_dev[i-num_days_train,:] = np.mean(data[i*min_to_day:(i + 1)*min_to_day, 1:9], axis = 0)\n",
    "        X_dev[i-num_days_train,1] = data[i*min_to_day, 1]\n",
    "        X_dev[i-num_days_train,2] = np.max(data[i*min_to_day:(i + 1)*min_to_day, 2])\n",
    "        X_dev[i-num_days_train,3] = np.max(data[i*min_to_day:(i + 1)*min_to_day, 3])\n",
    "        X_dev[i-num_days_train,4] = data[i*min_to_day, 4]\n",
    "    # For whether the price went up or down, new mean data is compared\n",
    "    for j in range(0, num_days_train-1):\n",
    "        Y_train[j,0] = (X_train[j,4] > X_train[j+1,4])\n",
    "    for k in range(0, num_days_dev-1):\n",
    "        Y_dev[k,0] = (X_dev[k,4] > X_dev[k+1,4])\n",
    "    \n",
    "    return X_train, Y_train, X_dev, Y_dev\n",
    "\n",
    "# Normalize Data to avoid one variable containing too much weight, since the\n",
    "# magnitude for all the variables changes drastically\n",
    "def normalize(data):\n",
    "    \n",
    "    row_sums = data.sum(axis = 1)\n",
    "    data = data/row_sums[:,np.newaxis]\n",
    "    \n",
    "    return data\n",
    "\n",
    "#First Try Model\n",
    "\n",
    "# Import required functions from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "\n",
    "# Get data file\n",
    "BTC_Price = import_data_file(bitcoin_data_filename)\n",
    "X, Y, X_dev, Y_dev = generate_min_dataset(BTC_Price, 10000, 10000) # generate minute dataset\n",
    "# X, Y, X_dev, Y_dev = generate_daily_dataset(BTC_Price, 10000, 128) # generate daily dataset\n",
    "X = normalize(X)\n",
    "X_dev = normalize(X_dev)\n",
    "\n",
    "# this is a 3 layer network, using binary cross entropy as the loss function and adam regularization. \n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim = size(X,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with batch sizes of 32 samples\n",
    "\n",
    "history = model.fit(X, Y, epochs = 100, batch_size = 32, validation_data = (X_dev, Y_dev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print final prediciton accuracy\n",
    "preds = model.evaluate(X_dev, Y_dev, batch_size=128, verbose=1, sample_weight=None)\n",
    "### END CODE HERE ###\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN model to compare with simple 3 layer NN\n",
    "\n",
    "# Import required functions from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization, LSTM\n",
    "\n",
    "# Get data file\n",
    "BTC_Price = import_data_file(bitcoin_data_filename)\n",
    "timesteps = 1440\n",
    "\n",
    "X, Y, X_dev, Y_dev = generate_min_dataset(BTC_Price, 10000, 10000)\n",
    "X = normalize(X)\n",
    "X_dev = normalize(X_dev)\n",
    "batch_size = 32\n",
    "\n",
    "# Specifically trying Long-Short term memory (LSTM) model others have suggested works for stock data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(8, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with batch sizes of 32 samples\n",
    "model.fit(X, Y, epochs = 20, batch_size = 32)\n",
    "score = model.evaluate(X_dev, Y_dev, batch_size=100)\n",
    "print(model.metrics_names + score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Accuracy of Lag Model to Test Polarity Baseline \n",
    "#Calculating 1 day lag shift\n",
    "BTC_Price['shift'] = BTC_Price['Up_Label'].shift(1)  # new column of \n",
    "BTC_Price['lag_correct'] = np.where(BTC_Price['Up_Label'] == BTC_Price['shift'],1,0)\n",
    "acc = BTC_Price['lag_correct'].sum()/BTC_Price['lag_correct'].size*100  #outputs accuracy\n",
    "\n",
    "# Plotting Lag Model over 25 minutes to depict Lag Model\n",
    "plt.plot(BTC_Price['Timestamp'],BTC_Price['Up_Label'],color = 'b', linewidth=1.0)\n",
    "plt.plot(BTC_Price['Timestamp'],BTC_Price['shift'],color = 'g', linewidth=1.0)\n",
    "plt.axis([1500000000, 1500001500,-0.1,1.1])\n",
    "plt.ylabel('Polarity Index',fontsize=12)\n",
    "plt.title('Lag Model',fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
